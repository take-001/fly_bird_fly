{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import flappy_bird_gymnasium\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import gc\n",
    "import numpy as np\n",
    "import pygame\n",
    "import itertools\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from collections import deque\n",
    "from enum import IntEnum\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Grayscale\n",
    "from flappy_bird_gymnasium.envs.flappy_bird_env import FlappyBirdEnv\n",
    "from flappy_bird_gymnasium.envs.flappy_bird_env import Actions\n",
    "from flappy_bird_gymnasium.envs import utils\n",
    "from flappy_bird_gymnasium.envs.lidar import LIDAR\n",
    "from flappy_bird_gymnasium.envs.constants import (\n",
    "    BACKGROUND_WIDTH,\n",
    "    BASE_WIDTH,\n",
    "    FILL_BACKGROUND_COLOR,\n",
    "    LIDAR_MAX_DISTANCE,\n",
    "    PIPE_HEIGHT,\n",
    "    PIPE_VEL_X,\n",
    "    PIPE_WIDTH,\n",
    "    PLAYER_ACC_Y,\n",
    "    PLAYER_FLAP_ACC,\n",
    "    PLAYER_HEIGHT,\n",
    "    PLAYER_MAX_VEL_Y,\n",
    "    PLAYER_PRIVATE_ZONE,\n",
    "    PLAYER_ROT_THR,\n",
    "    PLAYER_VEL_ROT,\n",
    "    PLAYER_WIDTH,\n",
    ")\n",
    "from typing import Dict, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "\n",
    "\n",
    "def new_render(self):\n",
    "    \"\"\"Renders the next frame.\"\"\"\n",
    "    if self.render_mode == \"rgb_array\":\n",
    "        self._draw_surface(show_score=False, show_rays=False)\n",
    "        # Flip the image to retrieve a correct aspect\n",
    "        return np.transpose(pygame.surfarray.array3d(self._surface), axes=(1, 0, 2))\n",
    "    else:\n",
    "        self._draw_surface(show_score=True, show_rays=False)\n",
    "        if self._display is None:\n",
    "            self._make_display()\n",
    "\n",
    "        self._update_display()\n",
    "        self._fps_clock.tick(self.metadata[\"render_fps\"])\n",
    "\n",
    "def new_step(\n",
    "    self,\n",
    "    action: Union[Actions, int],\n",
    ") -> Tuple[np.ndarray, float, bool, Dict]:\n",
    "    \"\"\"Given an action, updates the game state.\n",
    "\n",
    "    Args:\n",
    "        action (Union[FlappyBirdLogic.Actions, int]): The action taken by\n",
    "            the agent. Zero (0) means \"do nothing\" and one (1) means \"flap\".\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing, respectively:\n",
    "\n",
    "            * an observation (horizontal distance to the next pipe\n",
    "                difference between the player's y position and the next hole's\n",
    "                y position)\n",
    "            * a reward (alive = +0.1, pipe = +1.0, dead = -1.0)\n",
    "            * a status report (`True` if the game is over and `False`\n",
    "                otherwise)\n",
    "            * an info dictionary\n",
    "    \"\"\"\n",
    "    \"\"\"Given an action taken by the player, updates the game's state.\n",
    "\n",
    "    Args:\n",
    "        action (Union[FlappyBirdLogic.Actions, int]): The action taken by\n",
    "            the player.\n",
    "\n",
    "    Returns:\n",
    "        `True` if the player is alive and `False` otherwise.\n",
    "    \"\"\"\n",
    "    terminal = False\n",
    "    reward = None\n",
    "\n",
    "    self._sound_cache = None\n",
    "    if action == Actions.FLAP:\n",
    "        if self._player_y > -2 * PLAYER_HEIGHT:\n",
    "            self._player_vel_y = PLAYER_FLAP_ACC\n",
    "            self._player_flapped = True\n",
    "            self._sound_cache = \"wing\"\n",
    "\n",
    "    # check for score\n",
    "    player_mid_pos = self._player_x + PLAYER_WIDTH / 2\n",
    "    for pipe in self._upper_pipes:\n",
    "        pipe_mid_pos = pipe[\"x\"] + PIPE_WIDTH / 2\n",
    "        if pipe_mid_pos <= player_mid_pos < pipe_mid_pos + 4:\n",
    "            self._score += 1\n",
    "            reward = 1.0  # reward for passed pipe\n",
    "            self._sound_cache = \"point\"\n",
    "\n",
    "    # player_index base_x change\n",
    "    if (self._loop_iter + 1) % 3 == 0:\n",
    "        self._player_idx = next(self._player_idx_gen)\n",
    "\n",
    "    self._loop_iter = (self._loop_iter + 1) % 30\n",
    "    self._ground[\"x\"] = -((-self._ground[\"x\"] + 100) % self._base_shift)\n",
    "\n",
    "    # rotate the player\n",
    "    if self._player_rot > -90:\n",
    "        self._player_rot -= PLAYER_VEL_ROT\n",
    "\n",
    "    # player's movement\n",
    "    if self._player_vel_y < PLAYER_MAX_VEL_Y and not self._player_flapped:\n",
    "        self._player_vel_y += PLAYER_ACC_Y\n",
    "\n",
    "    if self._player_flapped:\n",
    "        self._player_flapped = False\n",
    "\n",
    "        # more rotation to cover the threshold\n",
    "        # (calculated in visible rotation)\n",
    "        self._player_rot = 45\n",
    "\n",
    "    self._player_y += min(\n",
    "        self._player_vel_y, self._ground[\"y\"] - self._player_y - PLAYER_HEIGHT\n",
    "    )\n",
    "\n",
    "    # move pipes to left\n",
    "    for up_pipe, low_pipe in zip(self._upper_pipes, self._lower_pipes):\n",
    "        up_pipe[\"x\"] += PIPE_VEL_X\n",
    "        low_pipe[\"x\"] += PIPE_VEL_X\n",
    "\n",
    "        # it is out of the screen\n",
    "        if up_pipe[\"x\"] < -PIPE_WIDTH:\n",
    "            new_up_pipe, new_low_pipe = self._get_random_pipe()\n",
    "            up_pipe[\"x\"] = new_up_pipe[\"x\"]\n",
    "            up_pipe[\"y\"] = new_up_pipe[\"y\"]\n",
    "            low_pipe[\"x\"] = new_low_pipe[\"x\"]\n",
    "            low_pipe[\"y\"] = new_low_pipe[\"y\"]\n",
    "\n",
    "    if self.render_mode == \"human\":\n",
    "        self.render()\n",
    "\n",
    "    obs, reward_private_zone = self._get_observation()\n",
    "    if reward is None:\n",
    "        if reward_private_zone is not None:\n",
    "            reward = float(reward_private_zone)\n",
    "        else:\n",
    "            reward = 0.1  # reward for staying alive\n",
    "\n",
    "    # check\n",
    "    if self._debug and self._use_lidar:\n",
    "        # sort pipes by the distance between pipe and agent\n",
    "        up_pipe = sorted(\n",
    "            self._upper_pipes,\n",
    "            key=lambda x: np.sqrt(\n",
    "                (self._player_x - x[\"x\"]) ** 2\n",
    "                + (self._player_y - (x[\"y\"] + PIPE_HEIGHT)) ** 2\n",
    "            ),\n",
    "        )[0]\n",
    "        # find ray closest to the obstacle\n",
    "        min_index = np.argmin(obs)\n",
    "        min_value = obs[min_index] * LIDAR_MAX_DISTANCE\n",
    "        # mean approach to the obstacle\n",
    "        if \"pipe_mean_value\" in self._statistics:\n",
    "            self._statistics[\"pipe_mean_value\"] = self._statistics[\n",
    "                \"pipe_mean_value\"\n",
    "            ] * 0.99 + min_value * (1 - 0.99)\n",
    "        else:\n",
    "            self._statistics[\"pipe_mean_value\"] = min_value\n",
    "\n",
    "        # Nearest to the pipe\n",
    "        if \"pipe_min_value\" in self._statistics:\n",
    "            if min_value < self._statistics[\"pipe_min_value\"]:\n",
    "                self._statistics[\"pipe_min_value\"] = min_value\n",
    "                self._statistics[\"pipe_min_index\"] = min_index\n",
    "        else:\n",
    "            self._statistics[\"pipe_min_value\"] = min_value\n",
    "            self._statistics[\"pipe_min_index\"] = min_index\n",
    "\n",
    "        # Nearest to the ground\n",
    "        diff = np.abs(self._player_y - self._ground[\"y\"])\n",
    "        if \"ground_min_value\" in self._statistics:\n",
    "            if diff < self._statistics[\"ground_min_value\"]:\n",
    "                self._statistics[\"ground_min_value\"] = diff\n",
    "        else:\n",
    "            self._statistics[\"ground_min_value\"] = diff\n",
    "\n",
    "    # agent touch the top of the screen as punishment\n",
    "    if self._player_y < 0:\n",
    "        reward = -0.5\n",
    "\n",
    "    # check for crash\n",
    "    if self._check_crash():\n",
    "        self._sound_cache = \"hit\"\n",
    "        reward = -1.0  # reward for dying\n",
    "        terminal = True\n",
    "        self._player_vel_y = 0\n",
    "        if self._debug and self._use_lidar:\n",
    "            if ((self._player_x + PLAYER_WIDTH) - up_pipe[\"x\"]) > (0 + 5) and (\n",
    "                self._player_x - up_pipe[\"x\"]\n",
    "            ) < PIPE_WIDTH:\n",
    "                print(\"BETWEEN PIPES\")\n",
    "            elif ((self._player_x + PLAYER_WIDTH) - up_pipe[\"x\"]) < (0 + 5):\n",
    "                print(\"IN FRONT OF\")\n",
    "            print(\n",
    "                f\"obs: [{self._statistics['pipe_min_index']},\"\n",
    "                f\"{self._statistics['pipe_min_value']},\"\n",
    "                f\"{self._statistics['pipe_mean_value']}],\"\n",
    "                f\"Ground: {self._statistics['ground_min_value']}\"\n",
    "            )\n",
    "\n",
    "    info = {\"score\": self._score}\n",
    "\n",
    "    return (\n",
    "        obs,\n",
    "        np.float32(reward),\n",
    "        terminal,\n",
    "        (self._score_limit is not None) and (self._score >= self._score_limit),\n",
    "        info,\n",
    "    )\n",
    "\n",
    "\n",
    "FlappyBirdEnv.render = new_render\n",
    "FlappyBirdEnv.step = new_step\n",
    "\n",
    "\n",
    "\n",
    "def smooth_data(data, window_size=100):\n",
    "    \"\"\"Apply a simple moving average smoothing to the data.\"\"\"\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "def plot_rewards_with_opacity(rewards_dict, title, xlabel, ylabel, img_name):\n",
    "\n",
    "    avg_rewards = {key: np.mean(rewards) for key, rewards in rewards_dict.items()} ##coefficients of variation\n",
    "    top3_keys = sorted(avg_rewards, key=avg_rewards.get, reverse=True)[:3]\n",
    "    \n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "    num_combinations = len(rewards_dict)\n",
    "    cmap = cm.get_cmap(\"cool\", num_combinations)\n",
    "    \n",
    "    # Loop through each hyperparameter combination and plot with a color from the colormap\n",
    "    for idx, (key, rewards) in enumerate(rewards_dict.items()):\n",
    "\n",
    "        smoothed_rewards = smooth_data(rewards, window_size=100)\n",
    "        color = cmap(idx)  # Get the color for this hyperparameter combination\n",
    "        # Adjust opacity for non-top3 combinations\n",
    "        alpha = 1.0 if key in top3_keys else 0.05\n",
    "        ax.plot(range(1, len(smoothed_rewards) + 1), smoothed_rewards, label=key, color=color, alpha=alpha,linewidth=0.7)\n",
    "    \n",
    "    # Set title with bold font\n",
    "    ax.set_title(title, fontweight='bold',fontsize=18)\n",
    "    ax.set_xlabel(xlabel,fontweight='bold')\n",
    "    ax.set_ylabel(ylabel,fontweight='bold')\n",
    "    \n",
    "    \n",
    "    # Place the legend in the bottom-right corner, remove title, and make it smaller\n",
    "    ax.legend(loc='center left', \n",
    "              bbox_to_anchor=(1.05, 0.5),  # Position the legend box outside to the right\n",
    "              borderaxespad=0., \n",
    "              fancybox=True, \n",
    "              fontsize='small', \n",
    "              markerscale=0.5, \n",
    "            )  # Make the title bold\n",
    "    fig.savefig(f'../img/{img_name}.png',dpi=600) \n",
    "    plt.tight_layout()  # Ensures the legend does not get clipped\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "######DDQN#####\n",
    "###############\n",
    "\n",
    "# Replay Memory to store experiences\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "# Dueling DQN Network Architecture\n",
    "class DuelingDQN(nn.Module):\n",
    "    def __init__(self, input_dim, action_space):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        # self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "\n",
    "        # Value Stream\n",
    "        self.value_stream = nn.Linear(128, 1)\n",
    "\n",
    "        # Advantage Stream\n",
    "        self.advantage_stream = nn.Linear(128, action_space)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "\n",
    "        # Calculate value and advantage\n",
    "        value = self.value_stream(x)\n",
    "        advantage = self.advantage_stream(x)\n",
    "\n",
    "        # Calculate Q-values\n",
    "        q_values = value + (advantage - advantage.mean(dim=1, keepdim=True))  # Normalize advantage\n",
    "        return q_values\n",
    "\n",
    "\n",
    "# DQN Agent Class with Dueling Architecture\n",
    "class DuelingDQNAgent:\n",
    "    def __init__(self, env, hyper):\n",
    "        self.env = env\n",
    "        self.state_dim = env.observation_space.shape[0]\n",
    "        self.action_space = env.action_space.n\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.learning_rate = hyper[\"learning_rate\"]\n",
    "        self.discount_factor = hyper[\"discount_factor\"]\n",
    "        self.epsilon = hyper[\"epsilon\"]\n",
    "        self.epsilon_decay = hyper[\"epsilon_decay\"]\n",
    "        self.epsilon_min = hyper[\"epsilon_min\"]\n",
    "        self.batch_size = hyper[\"batch_size\"]\n",
    "        self.memory_size = hyper[\"memory_size\"]\n",
    "        self.episodes = hyper[\"episodes\"]\n",
    "        self.target_update_freq = hyper[\"target_update_freq\"]\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Initialize policy and target networks with dueling architecture\n",
    "        self.policy_net = DuelingDQN(self.state_dim, self.action_space).to(self.device)\n",
    "        self.target_net = DuelingDQN(self.state_dim, self.action_space).to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "\n",
    "        # Optimizer and Replay Memory\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate)\n",
    "        self.memory = ReplayMemory(self.memory_size)\n",
    "\n",
    "    def select_action(self, state, testing=False):\n",
    "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
    "        if not testing and random.random() < self.epsilon:\n",
    "            return random.randint(0, self.action_space - 1)  # Random action\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "                return self.policy_net(state).argmax(dim=1).item()\n",
    "\n",
    "    def optimize_model(self):\n",
    "        \"\"\"Sample a batch from memory and optimize the policy network.\"\"\"\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch = self.memory.sample(self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        # Convert to tensors and move to device\n",
    "        states = torch.tensor(states, dtype=torch.float32).to(self.device)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).unsqueeze(1).to(self.device)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32).to(self.device)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
    "\n",
    "        # Compute Q-values and targets\n",
    "        q_values = self.policy_net(states).gather(1, actions)\n",
    "        next_q_values = self.target_net(next_states).max(1, keepdim=True)[0]\n",
    "        targets = rewards + (self.discount_factor * next_q_values * (1 - dones))\n",
    "\n",
    "        # Loss and backpropagation\n",
    "        loss = nn.MSELoss()(q_values, targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def train(self):\n",
    "        res = []\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        for episode in range(self.episodes):\n",
    "            state, _ = self.env.reset()\n",
    "            done = False\n",
    "            total_reward = 0.0\n",
    "            while not done:\n",
    "                # Select and execute action\n",
    "                action = self.select_action(state)\n",
    "                next_state, reward, done, _, _ = self.env.step(action)\n",
    "                self.memory.push(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "                # Optimize model\n",
    "                self.optimize_model()\n",
    "\n",
    "            # Update target network periodically\n",
    "            if episode % self.target_update_freq == 0:\n",
    "                self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "            # Decay epsilon\n",
    "            self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "            res.append(total_reward)\n",
    "            print(f\"Episode: {episode + 1}, Total Reward: {total_reward}, Epsilon: {self.epsilon:.4f}\")\n",
    "\n",
    "        self.env.close()\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "        return res\n",
    "\n",
    "    def test(self, num_episodes=10, render=\"human\"):\n",
    "        \"\"\"Test the trained policy with real-time rendering.\"\"\"\n",
    "        print(\"\\nTesting the trained policy...\\n\")\n",
    "        self.epsilon = 0.0  # Disable exploration\n",
    "        test_env = gymnasium.make(\"FlappyBird-v0\", render_mode=render, use_lidar=True)  # Render in \"human\" mode \n",
    "        total_rewards = []\n",
    "\n",
    "        for episode in range(num_episodes):\n",
    "            state, _ = test_env.reset()\n",
    "            done = False\n",
    "            total_reward = 0.0\n",
    "\n",
    "            while not done:\n",
    "                action = self.select_action(state, testing=True)\n",
    "                next_state, reward, done, _, _ = test_env.step(action)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "            total_rewards.append(total_reward)\n",
    "            print(f\"Test Episode: {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "        avg_reward = np.mean(total_rewards)\n",
    "        print(f\"\\nAverage Reward over {num_episodes} Test Episodes: {avg_reward}\")\n",
    "        test_env.close()\n",
    "        return total_rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "####DDQN++#####\n",
    "###############\n",
    "\n",
    "# Replay Memory to store experiences\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "# Dueling DQN Network Architecture\n",
    "class DDQN(nn.Module):\n",
    "    def __init__(self, input_dim, action_space):\n",
    "        super(DDQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        # self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "\n",
    "        # Value Stream\n",
    "        self.value_stream = nn.Linear(128, 1)\n",
    "\n",
    "        # Advantage Stream\n",
    "        self.advantage_stream = nn.Linear(128, action_space)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "\n",
    "        # Calculate value and advantage\n",
    "        value = self.value_stream(x)\n",
    "        advantage = self.advantage_stream(x)\n",
    "\n",
    "        # Calculate Q-values\n",
    "        q_values = value + (advantage - advantage.mean(dim=1, keepdim=True))  # Normalize advantage\n",
    "        return q_values\n",
    "\n",
    "\n",
    "# DQN Agent Class with Dueling Architecture\n",
    "class DDQNppAgent:\n",
    "    def __init__(self, \n",
    "                 env, \n",
    "                hyper ={\n",
    "                          \"learning_rate\": 0.001,\n",
    "                          \"discount_factor\" : 0.99,\n",
    "                          \"epsilon\" : 1.0,\n",
    "                          \"epsilon_decay\" :0.999,\n",
    "                          \"epsilon_min\" : 0.01,\n",
    "                          \"batch_size\" : 64,\n",
    "                          \"memory_size\" : 10000,\n",
    "                          \"episodes\" : 100000,\n",
    "                          \"target_update_freq\" : 10,\n",
    "                          \"rho\" :1.0,\n",
    "                          \"kappa\" : 1.0,\n",
    "                          \"eps_update_freq\":100\n",
    "                        }):\n",
    "        self.env = env\n",
    "        self.state_dim = env.observation_space.shape[0]\n",
    "        self.action_space = env.action_space.n\n",
    "\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.learning_rate = hyper[\"learning_rate\"]\n",
    "        self.discount_factor = hyper[\"discount_factor\"]\n",
    "        self.epsilon = hyper[\"epsilon\"]\n",
    "        self.epsilon_decay = hyper[\"epsilon_decay\"]\n",
    "        self.epsilon_min = hyper[\"epsilon_min\"]\n",
    "        self.batch_size = hyper[\"batch_size\"]\n",
    "        self.memory_size = hyper[\"memory_size\"]\n",
    "        self.episodes = hyper[\"episodes\"]\n",
    "        self.target_update_freq = hyper[\"target_update_freq\"]\n",
    "        self.rho = hyper[\"rho\"]\n",
    "        self.kappa = hyper[\"kappa\"]\n",
    "        self.eps_update_freq=hyper[\"eps_update_freq\"]\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Initialize policy and target networks with dueling architecture\n",
    "        self.policy_net = DDQN(self.state_dim, self.action_space).to(self.device)\n",
    "        self.target_net = DDQN(self.state_dim, self.action_space).to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "\n",
    "        # Optimizer and Replay Memory\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate)\n",
    "        self.memory = ReplayMemory(self.memory_size)\n",
    "\n",
    "\n",
    "\n",
    "    def select_action(self, state, testing=False,oracle=1):\n",
    "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
    "        if not testing and random.random() < self.epsilon:\n",
    "            return self.oracle(random.randint(0, self.action_space - 1),oracle ) # Random action\n",
    "\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "                return self.oracle(self.policy_net(state).argmax(dim=1).item(),oracle)\n",
    "    \n",
    "    def oracle(self, action,option=1):\n",
    "        next_state, reward, done, _, _ = self.env.step(action)\n",
    "        if done :\n",
    "            action = (action+option)%2\n",
    "\n",
    "        return action\n",
    "        \n",
    "\n",
    "    def optimize_model(self):\n",
    "        \"\"\"Sample a batch from memory and optimize the policy network.\"\"\"\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch = self.memory.sample(self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        # Convert to tensors and move to device\n",
    "        states = torch.tensor(states, dtype=torch.float32).to(self.device)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).unsqueeze(1).to(self.device)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32).to(self.device)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
    "\n",
    "        # Compute Q-values and targets\n",
    "        q_values = self.policy_net(states).gather(1, actions)\n",
    "        next_q_values = self.target_net(next_states).max(1, keepdim=True)[0]\n",
    "        targets = rewards + (self.discount_factor * next_q_values * (1 - dones))\n",
    "\n",
    "        # Loss and backpropagation\n",
    "        loss = nn.MSELoss()(q_values, targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def train(self):\n",
    "        res = []\n",
    "        res=[]\n",
    "        reward_trace=np.float32(0.0)\n",
    "        old_reward_trace=np.float32(0.0)\n",
    "        counter=0\n",
    "  \n",
    "\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        for episode in range(self.episodes):\n",
    "            state, _ = self.env.reset()\n",
    "            done = False\n",
    "            total_reward = np.float32(0.0)\n",
    "\n",
    "\n",
    "            while not done:\n",
    "                # Select and execute action\n",
    "                action = self.select_action(state)\n",
    "                next_state, reward, done, _, _ = self.env.step(action)\n",
    "                self.memory.push(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "                # Optimize model\n",
    "                self.optimize_model()\n",
    "\n",
    "            # Update target network periodically\n",
    "            if episode % self.target_update_freq == 0:\n",
    "                self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "            # Decay epsilon\n",
    "            self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "            if abs(self.epsilon-self.epsilon_min) < 1e-4 :\n",
    "\n",
    "                reward_trace+=total_reward\n",
    "                counter+=1\n",
    "                if counter % self.eps_update_freq== 0:\n",
    "                    if (reward_trace-old_reward_trace)/self.eps_update_freq<self.kappa:\n",
    "                        self.epsilon = self.rho\n",
    "                        reward_trace=np.float32(0.0)\n",
    "                        old_reward_trace=np.float32(0.0)\n",
    "                    \n",
    "                    counter=0\n",
    "                    old_reward_trace=reward_trace\n",
    "                    reward_trace=np.float32(0.0)\n",
    "\n",
    "\n",
    "            res.append(total_reward)\n",
    "            print(f\"Episode: {episode + 1}, Total Reward: {total_reward}, Epsilon: {self.epsilon:.4f}\")\n",
    "\n",
    "        self.env.close()\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "        return res\n",
    "\n",
    "    def test(self, num_episodes=10, render=\"human\"):\n",
    "        \"\"\"Test the trained policy with real-time rendering.\"\"\"\n",
    "        print(\"\\nTesting the trained policy...\\n\")\n",
    "        self.epsilon = 0.0  # Disable exploration\n",
    "        test_env = gymnasium.make(\"FlappyBird-v0\", render_mode=render, use_lidar=True)  # Render in \"human\" mode \n",
    "        total_rewards = []\n",
    "\n",
    "        for episode in range(num_episodes):\n",
    "            state, _ = test_env.reset()\n",
    "            done = False\n",
    "            total_reward = 0.0\n",
    "\n",
    "            while not done:\n",
    "                action = self.select_action(state, testing=True,oracle=0)\n",
    "                next_state, reward, done, _, _ = test_env.step(action)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "            total_rewards.append(total_reward)\n",
    "            print(f\"Test Episode: {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "        avg_reward = np.mean(total_rewards)\n",
    "        print(f\"\\nAverage Reward over {num_episodes} Test Episodes: {avg_reward}\")\n",
    "        test_env.close()\n",
    "        return total_rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "######EAC#######\n",
    "################\n",
    "\n",
    "\n",
    "class ActorCriticNet(nn.Module):\n",
    "    def __init__(self, input_dim, action_space):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(128, action_space)\n",
    "        )\n",
    "        self.critic = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared = self.shared(x)\n",
    "        return F.softmax(self.actor(shared), dim=-1), self.critic(shared)\n",
    "\n",
    "class EAC_agent:\n",
    "    def __init__(self, env, config):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.env = env\n",
    "        self.state_dim = env.observation_space.shape[0]\n",
    "        self.action_space = env.action_space.n\n",
    "        \n",
    "        # Parameters\n",
    "        self.actor_lr = config.get('actor_lr', 0.001)\n",
    "        self.critic_lr = config.get('critic_lr', 0.005)\n",
    "        self.gamma = config.get('gamma', 0.99)\n",
    "        self.gae_lambda = config.get('gae_lambda', 0.95)\n",
    "        self.entropy_coef = config.get('entropy_coef', 0.01)\n",
    "        self.value_loss_coef = config.get('value_loss_coef', 0.5)\n",
    "        self.max_grad_norm = config.get('max_grad_norm', 0.5)\n",
    "        self.episodes = config.get('episodes', 5000)\n",
    "        \n",
    "        self.network = ActorCriticNet(self.state_dim, self.action_space).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.network.parameters(), lr=self.actor_lr)\n",
    "        self.critic_optimizer = optim.Adam(self.network.parameters(), lr=self.critic_lr)\n",
    "        \n",
    "        self.log_probs = []\n",
    "        self.values = []\n",
    "        self.rewards = []\n",
    "        self.masks = []\n",
    "\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            probs, value = self.network(state)\n",
    "            dist = Categorical(probs)\n",
    "            action = dist.sample()\n",
    "            log_prob = dist.log_prob(action)\n",
    "        \n",
    "        return action.item(), log_prob.item(), value.item()\n",
    "\n",
    "    def compute_gae(self):\n",
    "        returns = []\n",
    "        gae = 0\n",
    "        for step in reversed(range(len(self.rewards))):\n",
    "            if step == len(self.rewards) - 1:\n",
    "                next_value = 0\n",
    "            else:\n",
    "                next_value = self.values[step + 1]\n",
    "                \n",
    "            delta = self.rewards[step] + self.gamma * next_value * self.masks[step] - self.values[step]\n",
    "            gae = delta + self.gamma * self.gae_lambda * self.masks[step] * gae\n",
    "            returns.insert(0, gae + self.values[step])\n",
    "            \n",
    "        return torch.FloatTensor(returns).to(self.device)\n",
    "\n",
    "    def train_step(self):\n",
    "        returns = self.compute_gae()\n",
    "        \n",
    "        values = torch.FloatTensor(self.values).to(self.device)\n",
    "        log_probs = torch.FloatTensor(self.log_probs).to(self.device)\n",
    "        advantages = returns - values\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "        \n",
    "        states = torch.FloatTensor(self.states).to(self.device)\n",
    "        actions = torch.LongTensor(self.actions).to(self.device)\n",
    "        \n",
    "        # Forward pass\n",
    "        new_probs, new_values = self.network(states)\n",
    "        dist = Categorical(new_probs)\n",
    "        new_log_probs = dist.log_prob(actions)\n",
    "        entropy = dist.entropy().mean()\n",
    "        \n",
    "        # Actor loss\n",
    "        ratio = torch.exp(new_log_probs - log_probs)\n",
    "        surr1 = ratio * advantages\n",
    "        actor_loss = -(surr1.mean() + self.entropy_coef * entropy)\n",
    "        \n",
    "        # Critic loss\n",
    "        critic_loss = self.value_loss_coef * F.mse_loss(new_values.squeeze(-1), returns)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = actor_loss + critic_loss\n",
    "        \n",
    "        # Optimize\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.network.parameters(), self.max_grad_norm)\n",
    "        self.actor_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        # Clear memory\n",
    "        self.log_probs.clear()\n",
    "        self.values.clear()\n",
    "        self.rewards.clear()\n",
    "        self.masks.clear()\n",
    "        self.states.clear()\n",
    "        self.actions.clear()\n",
    "\n",
    "    def train(self):\n",
    "        rewards_history = []\n",
    "        \n",
    "        for episode in range(self.episodes):\n",
    "            state, _ = self.env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            \n",
    "            self.states = []\n",
    "            self.actions = []\n",
    "            \n",
    "            while not done:\n",
    "                action, log_prob, value = self.select_action(state)\n",
    "                next_state, reward, done, truncated, _ = self.env.step(action)\n",
    "                \n",
    "                self.states.append(state)\n",
    "                self.actions.append(action)\n",
    "                self.rewards.append(reward)\n",
    "                self.log_probs.append(log_prob)\n",
    "                self.values.append(value)\n",
    "                self.masks.append(1 - done)\n",
    "                \n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                \n",
    "                if truncated:\n",
    "                    break\n",
    "            \n",
    "            self.train_step()\n",
    "            rewards_history.append(total_reward)\n",
    "            \n",
    "            if episode % 100 == 0:\n",
    "                avg_reward = np.mean(rewards_history[-100:])\n",
    "                print(f\"Episode {episode}, Reward: {total_reward:.2f}, Avg: {avg_reward:.2f}\")\n",
    "        \n",
    "        return rewards_history\n",
    "\n",
    "    def test(self, num_episodes=10,render=\"human\"):\n",
    "        test_env = gymnasium.make(\"FlappyBird-v0\", render_mode=render,use_lidar=True)  # Render in \"human\" mode \n",
    "        total_rewards = []\n",
    "        for episode in range(num_episodes):\n",
    "            state, _ = test_env.reset()\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    probs, _ = self.network(state)\n",
    "                action = probs.argmax().item()\n",
    "                state, reward, done, truncated, _ = test_env.step(action)\n",
    "                total_reward += reward\n",
    "                if truncated:\n",
    "                    break\n",
    "            \n",
    "            total_rewards.append(total_reward)\n",
    "            print(f\"Test Episode {episode}, Total Reward: {total_reward}\")\n",
    "        \n",
    "        print(f\"Average Test Reward: {np.mean(total_rewards):.2f}\")\n",
    "        return total_rewards\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "######EAC+######\n",
    "################\n",
    "\n",
    "\n",
    "class ActorCriticNet(nn.Module):\n",
    "    def __init__(self, input_dim, action_space):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(128, action_space)\n",
    "        )\n",
    "        self.critic = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared = self.shared(x)\n",
    "        return F.softmax(self.actor(shared), dim=-1), self.critic(shared)\n",
    "\n",
    "class EAC_plus_agent:\n",
    "    def __init__(self, env, config):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.env = env\n",
    "        self.state_dim = env.observation_space.shape[0]\n",
    "        self.action_space = env.action_space.n\n",
    "        \n",
    "        # Parameters\n",
    "        self.actor_lr = config.get('actor_lr', 0.001)\n",
    "        self.critic_lr = config.get('critic_lr', 0.005)\n",
    "        self.gamma = config.get('gamma', 0.99)\n",
    "        self.gae_lambda = config.get('gae_lambda', 0.95)\n",
    "        self.entropy_coef = config.get('entropy_coef', 0.01)\n",
    "        self.value_loss_coef = config.get('value_loss_coef', 0.5)\n",
    "        self.max_grad_norm = config.get('max_grad_norm', 0.5)\n",
    "        self.episodes = config.get('episodes', 5000)\n",
    "        \n",
    "        self.network = ActorCriticNet(self.state_dim, self.action_space).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.network.parameters(), lr=self.actor_lr)\n",
    "        self.critic_optimizer = optim.Adam(self.network.parameters(), lr=self.critic_lr)\n",
    "        \n",
    "        self.log_probs = []\n",
    "        self.values = []\n",
    "        self.rewards = []\n",
    "        self.masks = []\n",
    "\n",
    "    def oracle(self, action,option=1):\n",
    "        next_state, reward, done, _, _ = self.env.step(action)\n",
    "        if done :\n",
    "            action = (action+option)%2\n",
    "\n",
    "        return action\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            probs, value = self.network(state)\n",
    "            dist = Categorical(probs)\n",
    "            action =self.oracle(dist.sample())\n",
    "            log_prob = dist.log_prob(action)\n",
    "        \n",
    "        return action.item(), log_prob.item(), value.item()\n",
    "\n",
    "    def compute_gae(self):\n",
    "        returns = []\n",
    "        gae = 0\n",
    "        for step in reversed(range(len(self.rewards))):\n",
    "            if step == len(self.rewards) - 1:\n",
    "                next_value = 0\n",
    "            else:\n",
    "                next_value = self.values[step + 1]\n",
    "                \n",
    "            delta = self.rewards[step] + self.gamma * next_value * self.masks[step] - self.values[step]\n",
    "            gae = delta + self.gamma * self.gae_lambda * self.masks[step] * gae\n",
    "            returns.insert(0, gae + self.values[step])\n",
    "            \n",
    "        return torch.FloatTensor(returns).to(self.device)\n",
    "\n",
    "    def train_step(self):\n",
    "        returns = self.compute_gae()\n",
    "        \n",
    "        values = torch.FloatTensor(self.values).to(self.device)\n",
    "        log_probs = torch.FloatTensor(self.log_probs).to(self.device)\n",
    "        advantages = returns - values\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "        \n",
    "        states = torch.FloatTensor(self.states).to(self.device)\n",
    "        actions = torch.LongTensor(self.actions).to(self.device)\n",
    "        \n",
    "        # Forward pass\n",
    "        new_probs, new_values = self.network(states)\n",
    "        dist = Categorical(new_probs)\n",
    "        new_log_probs = dist.log_prob(actions)\n",
    "        entropy = dist.entropy().mean()\n",
    "        \n",
    "        # Actor loss\n",
    "        ratio = torch.exp(new_log_probs - log_probs)\n",
    "        surr1 = ratio * advantages\n",
    "        actor_loss = -(surr1.mean() + self.entropy_coef * entropy)\n",
    "        \n",
    "        # Critic loss\n",
    "        critic_loss = self.value_loss_coef * F.mse_loss(new_values.squeeze(-1), returns)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = actor_loss + critic_loss\n",
    "        \n",
    "        # Optimize\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.network.parameters(), self.max_grad_norm)\n",
    "        self.actor_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        # Clear memory\n",
    "        self.log_probs.clear()\n",
    "        self.values.clear()\n",
    "        self.rewards.clear()\n",
    "        self.masks.clear()\n",
    "        self.states.clear()\n",
    "        self.actions.clear()\n",
    "\n",
    "    def train(self):\n",
    "        rewards_history = []\n",
    "        \n",
    "        for episode in range(self.episodes):\n",
    "            state, _ = self.env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            \n",
    "            self.states = []\n",
    "            self.actions = []\n",
    "            \n",
    "            while not done:\n",
    "                action, log_prob, value = self.select_action(state)\n",
    "                next_state, reward, done, truncated, _ = self.env.step(action)\n",
    "                \n",
    "                self.states.append(state)\n",
    "                self.actions.append(action)\n",
    "                self.rewards.append(reward)\n",
    "                self.log_probs.append(log_prob)\n",
    "                self.values.append(value)\n",
    "                self.masks.append(1 - done)\n",
    "                \n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                \n",
    "                if truncated:\n",
    "                    break\n",
    "            \n",
    "            self.train_step()\n",
    "            rewards_history.append(total_reward)\n",
    "            \n",
    "            if episode % 100 == 0:\n",
    "                avg_reward = np.mean(rewards_history[-100:])\n",
    "                print(f\"Episode {episode}, Reward: {total_reward:.2f}, Avg: {avg_reward:.2f}\")\n",
    "        \n",
    "        return rewards_history\n",
    "\n",
    "    def test(self, num_episodes=10,render=\"human\"):\n",
    "        test_env = gymnasium.make(\"FlappyBird-v0\", render_mode=render,use_lidar=True)  # Render in \"human\" mode \n",
    "        total_rewards = []\n",
    "        for episode in range(num_episodes):\n",
    "            state, _ = test_env.reset()\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    probs, _ = self.network(state)\n",
    "                action = probs.argmax().item()\n",
    "                state, reward, done, truncated, _ = test_env.step(action)\n",
    "                total_reward += reward\n",
    "                if truncated:\n",
    "                    break\n",
    "            \n",
    "            total_rewards.append(total_reward)\n",
    "            print(f\"Test Episode {episode}, Total Reward: {total_reward}\")\n",
    "        \n",
    "        print(f\"Average Test Reward: {np.mean(total_rewards):.2f}\")\n",
    "        return total_rewards\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gymnasium.make(\"FlappyBird-v0\", render_mode=\"rgb_array\", use_lidar=True)\n",
    "\n",
    "\n",
    "hyper_eac = {\n",
    "   \"actor_lr\": 0.0005,\n",
    "   \"critic_lr\": 0.001, \n",
    "   \"gamma\": 0.99,\n",
    "   \"gae_lambda\": 0.9,\n",
    "   \"entropy_coef\": 0.05,\n",
    "   \"value_loss_coef\": 1.0,\n",
    "   \"max_grad_norm\": 0.5,\n",
    "   \"episodes\": 99500\n",
    "}\n",
    "\n",
    "hyper_eacp = {\n",
    "   \"actor_lr\": 0.0005,\n",
    "   \"critic_lr\": 0.001, \n",
    "   \"gamma\": 0.99,\n",
    "   \"gae_lambda\": 0.9,\n",
    "   \"entropy_coef\": 0.05,\n",
    "   \"value_loss_coef\": 1.0,\n",
    "   \"max_grad_norm\": 0.5,\n",
    "   \"episodes\": 99500\n",
    "}\n",
    "\n",
    "hyper_ddqn = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"discount_factor\": 0.999,\n",
    "    \"epsilon\": 1.0,\n",
    "    \"epsilon_decay\": 0.999,\n",
    "    \"epsilon_min\": 0.01,\n",
    "    \"batch_size\": 64,\n",
    "    \"memory_size\": 10000,\n",
    "    \"episodes\": 99500,\n",
    "    \"target_update_freq\": 10\n",
    "}\n",
    "\n",
    "hyper_ddqnpp = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"discount_factor\": 0.99,\n",
    "    \"epsilon\": 1.0,\n",
    "    \"epsilon_decay\": 0.999,\n",
    "    \"epsilon_min\": 0.01,\n",
    "    \"batch_size\": 64,\n",
    "    \"memory_size\": 10000,\n",
    "    \"episodes\": 99500,\n",
    "    \"target_update_freq\": 10,\n",
    "    \"rho\":0.2,\n",
    "    \"kappa\":0.0,\n",
    "    \"eps_update_freq\":[10,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m exp_res \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m test_res \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "exp_res = {}\n",
    "test_res = {}\n",
    "\n",
    "eac_agent = EAC_agent(env, hyper_eac)\n",
    "ddqn_agent = DuelingDQNAgent(env, hyper_ddqn)\n",
    "ddqnpp_agent = DDQNppAgent(env,hyper_ddqnpp)\n",
    "eacp_agent=EAC_plus_agent(env,hyper_eacp)\n",
    "\n",
    "agents={\"EAC\": eac_agent,\"EAC+\":eacp_agent,\"DDQN\" : ddqn_agent, \"DDQN++\":ddqnpp_agent}\n",
    "\n",
    "for i in [\"EAC\",\"EAC+\"]:\n",
    "    exp_key=i\n",
    "\n",
    "    agent = agents[i]\n",
    "    exp_res[exp_key] = agent.train()\n",
    "    test_res[exp_key] = agent.test(num_episodes=5000, render=None)\n",
    "    agents[i] =agent\n",
    "    with open(\"../exp_data/comparison_tr.pkl\", \"wb\") as f:\n",
    "        pickle.dump(exp_res, f)\n",
    "    with open(\"../exp_data/comparison_test.pkl\", \"wb\") as f:\n",
    "        pickle.dump(test_res, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EAC': [np.float32(-5.1000013)],\n",
       " 'EAC+': [np.float32(-3.3999996)],\n",
       " 'DDQN': [np.float32(-8.1)],\n",
       " 'DDQN++': [np.float32(-3.3999996)]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../exp_data/comparison_tr.pkl\", \"rb\") as f:\n",
    "   exp_res = pickle.load(f)\n",
    "exp_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_382819/3418667986.py:253: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap(\"cool\", num_combinations)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"../exp_data/comparison_tr.pkl\", \"rb\") as f:\n",
    "   exp_res = pickle.load(f)\n",
    "with open(\"../exp_data/comparison_test.pkl\", \"rb\") as f:\n",
    "   test_res = pickle.load(f)\n",
    "plot_rewards_with_opacity(exp_res, \"Training Rewards (Top3, Avg.)\", \"Episode\", \"Reward\",\"eac_p_tr.png\")\n",
    "\n",
    "# Plot for test_res (test rewards)\n",
    "plot_rewards_with_opacity(test_res, \"Test Rewards (Top3, Avg.)\", \"Episode\", \"Reward\",\"eac_p_test.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flappy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
